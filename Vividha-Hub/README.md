# Vividha Hub
AI-Powered Multilingual Video Dubbing & Subtitling Engine

## Overview
Vividha Hub is an AI-driven video localization system that automates:

‚Ä¢ Speech transcription using OpenAI Whisper  
‚Ä¢ Speaker diarization using Pyannote  
‚Ä¢ Voice cloning using Coqui XTTS-v2  
‚Ä¢ Background music preservation using Demucs  
‚Ä¢ Subtitle rendering with language-specific fonts  
‚Ä¢ CUDA-accelerated video rendering with FFmpeg  

The system reduces localization costs by up to 90% and processes videos 10x faster than traditional manual workflows.

---

## Key Features

- üéô Speaker-preserving voice cloning
- üåç Multilingual dubbing (17+ languages)
- üéµ Background music retention
- ‚ö° GPU optimized pipeline (70‚Äì80% utilization)
- üé¨ Automatic subtitle generation
- üîÅ Adaptive speech rate synchronization

---

## Architecture

Video Upload  
‚Üí Audio Extraction  
‚Üí Whisper Transcription  
‚Üí Translation  
‚Üí Speaker Diarization  
‚Üí XTTS Voice Cloning  
‚Üí Time-Stretch Synchronization  
‚Üí Audio Mixing  
‚Üí Final Video Rendering  

---

## Tech Stack

Backend:
- Python
- PyTorch
- OpenAI Whisper
- Pyannote.audio
- Coqui XTTS-v2
- Demucs
- Librosa
- MoviePy
- FFmpeg (CUDA)

Frontend:
- HTML
- CSS
- JavaScript
- Electron (Node.js)

---

## Setup Instructions

### 1. Clone Repository

git clone https://github.com/Pushkar0655/Vividha-Hub.git
cd Vividha-Hub
### 2. Install Backend Dependencies
pip install -r requirements.txt

### 3. Set HuggingFace Token

Windows:
set HF_TOKEN=your_token_here

Mac/Linux:
export HF_TOKEN=your_token_here

### 4. Run Backend
python backend/backend.py --video sample.mp4 --input_lang english --audio_lang hindi --subtitle_lang german

### 5. Run Frontend
npm install
npm start

---

## Demo Videos

See project demonstrations in docs/ or Google Drive links.

---

## Research & Innovation

- Speaker-aware multilingual dubbing
- Dynamic speech duration alignment
- Integrated background audio preservation
- End-to-end automated pipeline

---

## Future Scope

- Lip-sync integration (Wav2Lip)
- Standalone desktop application
- Additional language support
- API deployment

---

## License
Open-source for educational and research purposes.


